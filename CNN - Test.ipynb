{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import pandas as pd\n",
    "import matplotlib as mplt\n",
    "import re\n",
    "from keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'/home/josheen/projects/def-vinay/josheen/DL/Figure13model/runs_excel_files'\n",
    "dfs = []\n",
    "for runs in os.listdir(directory):\n",
    "    R = pd.read_excel(os.path.join(directory,runs))\n",
    "    rnum = os.path.splitext(runs)[0]\n",
    "    R.head()\n",
    "    R['Run'] = int(rnum[1])\n",
    "    R.head()\n",
    "    dfs.append(R)\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = \"/home/josheen/projects/def-vinay/josheen/DL/Figure13model/mapped_data/AllRunsmapped.csv\"\n",
    "directory = \"/home/josheen/projects/def-vinay/josheen/DL/\"\n",
    "df = pd.read_csv(FileName)\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    address = row['Address']\n",
    "    new = address.replace(\"\\\\\", \"/\")\n",
    "    add_index = address.find('Figure13model')\n",
    "    new_filename = os.path.join(directory, new[add_index:])\n",
    "    df.at[index, 'Address'] = new_filename\n",
    "    \n",
    "df.to_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 6 ... 6 3 7]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "left=115\n",
    "top=35\n",
    "right=243\n",
    "bottom=163\n",
    "\n",
    "train_files = []\n",
    "y_train = []\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['Element'] == 'Zinc':\n",
    "        y_train.append(row['Recovery']) \n",
    "        img = load_img(row['Address'])  # this is a PIL image\n",
    "\n",
    "        img1 = img.crop((left,top,right,bottom))\n",
    "\n",
    "        #img2 =img1.thumbnail((128, 128))\n",
    "        x = img_to_array(img1)\n",
    "        #x = x.reshape((3, 128, 128))\n",
    "        #x = (x - 128.0) / 128.0\n",
    "        x = (x - 255.0) / 255.0\n",
    "        dataset.append(x)\n",
    "    else:\n",
    "        pass\n",
    "y_train1 = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9227f49d07cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Recovery'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Recovery'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is a PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "dataset = test\n",
    "y_train1 = test['Recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1237, Val set size: 155, Test set size: 155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "num_classes = 8\n",
    "categorical_train = []\n",
    "for val in y_train1:\n",
    "    if val <= 5:\n",
    "        categorical_train.append(0)\n",
    "    elif val > 5 and val <= 10:\n",
    "        categorical_train.append(1)\n",
    "    elif val > 10 and val<= 15:\n",
    "        categorical_train.append(2)\n",
    "    elif val > 15 and val<= 20:\n",
    "        categorical_train.append(3)\n",
    "    elif val > 20 and val<= 25:\n",
    "        categorical_train.append(4)\n",
    "    elif val > 25 and val <= 30:\n",
    "        categorical_train.append(5)\n",
    "    elif val > 30 and val <= 35:\n",
    "        categorical_train.append(6)\n",
    "    elif val >35:\n",
    "        categorical_train.append(7)\n",
    "    y_train = categorical_train\n",
    "\n",
    "test_to_train=0.2\n",
    "val_to_test=0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=test_to_train, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=val_to_test, random_state=33)\n",
    "\n",
    "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained CNN - VGG16 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes: we should look into making generators, accuracy does not seem to go higher than MAE = 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 16,820,584\n",
      "Trainable params: 2,105,896\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top=False, input_shape=(128,128,3))\n",
    "conv_base.trainable = False \n",
    "CNN = models.Sequential()\n",
    "CNN.add(conv_base)\n",
    "CNN.add(layers.Flatten())\n",
    "CNN.add(layers.Dense(256, activation='relu'))\n",
    "CNN.add(layers.Dropout(0.2))\n",
    "CNN.add(layers.Dense(32, activation='relu'))\n",
    "CNN.add(layers.Dropout(0.3))\n",
    "CNN.add(layers.Dense(8, activation = 'softmax'))\n",
    "CNN.summary()\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "CNN.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "39/39 [==============================] - 38s 977ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 2/75\n",
      "39/39 [==============================] - 38s 965ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.5938 - val_mae: 3.9414\n",
      "Epoch 3/75\n",
      "39/39 [==============================] - 37s 961ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.5938 - val_mae: 3.9414\n",
      "Epoch 4/75\n",
      "39/39 [==============================] - 37s 958ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.5146 - val_mae: 3.9297\n",
      "Epoch 5/75\n",
      "39/39 [==============================] - 37s 956ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 6/75\n",
      "39/39 [==============================] - 37s 958ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 7/75\n",
      "39/39 [==============================] - 37s 960ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 8/75\n",
      "39/39 [==============================] - 37s 958ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 9/75\n",
      "39/39 [==============================] - 37s 961ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 10/75\n",
      "39/39 [==============================] - 37s 958ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4229 - val_mae: 3.9219\n",
      "Epoch 11/75\n",
      "39/39 [==============================] - 37s 959ms/step - loss: 28.9160 - mae: 5.2469 - val_loss: 19.4727 - val_mae: 3.9258\n",
      "Epoch 12/75\n",
      "37/39 [===========================>..] - ETA: 1s - loss: 28.8775 - mae: 5.2449"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-1c21b2ccb6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/josheen/projects/def-vinay/josheen/DL/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CNN.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "my_callbacks = EarlyStopping(monitor=\"mean_absolute_error\", patience=6, mode=\"auto\")\n",
    "X_val = np.array(X_val)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "CNN.fit(X_train, y_train, batch_size=32,epochs=75,validation_data=(X_val, y_val))\n",
    "model = CNN.save('/home/josheen/projects/def-vinay/josheen/DL/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_train=0.2\n",
    "val_to_test=0.5\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['Address'], y_train1, test_size=test_to_train, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=val_to_test, random_state=33)\n",
    "\n",
    "train_gen = pd.DataFrame(X_train, columns=['Address'])\n",
    "train_gen['Recovery'] = y_train\n",
    "\n",
    "test_gen = pd.DataFrame(X_test, columns=['Address'])\n",
    "test_gen['Recovery'] = y_test\n",
    "\n",
    "val_gen = pd.DataFrame(X_val, columns=['Address'])\n",
    "val_gen['Recovery'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider splitting from 0-3 3-6 6-9 9-12 12-15 15-18 18-21 7 classes\n",
    "num_classes = 8\n",
    "for gen in [train_gen, test_gen, val_gen]:\n",
    "    categorical_train = []\n",
    "    for index, row in gen.iterrows():\n",
    "        val = row['Recovery']\n",
    "        if val <= 5:\n",
    "            categorical_train.append(0)\n",
    "        elif val > 5 and val <= 10:\n",
    "            categorical_train.append(1)\n",
    "        elif val > 10 and val<= 15:\n",
    "            categorical_train.append(2)\n",
    "        elif val > 15 and val<= 20:\n",
    "            categorical_train.append(3)\n",
    "        elif val > 20 and val<= 25:\n",
    "            categorical_train.append(4)\n",
    "        elif val > 25 and val <= 30:\n",
    "            categorical_train.append(5)\n",
    "        elif val > 30 and val <= 35:\n",
    "            categorical_train.append(6)\n",
    "        elif val >35:\n",
    "            categorical_train.append(7)\n",
    "    gen['Recovery'] = categorical_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_gen['Recovery'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2055 validated image filenames.\n",
      "Found 257 validated image filenames.\n",
      "Found 257 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255, rotation_range = 5, width_shift_range = 0.05, height_shift_range = 0.05, shear_range=0.05,\n",
    "    zoom_range=0.08, horizontal_flip = True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_gen, directory = None, x_col = 'Address', y_col = 'Recovery', target_size = (128,128),class_mode = 'raw')\n",
    "test_generator = test_datagen.flow_from_dataframe(test_gen, directory = None, x_col = 'Address', y_col = 'Recovery', target_size = (128,128), class_mode = 'raw')\n",
    "val_generator = val_datagen.flow_from_dataframe(val_gen, directory = None, x_col = 'Address', y_col = 'Recovery', target_size = (128,128), class_mode = 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras import Model \n",
    "\n",
    "initialWeights = keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=None)\n",
    "num_of_classes = 8\n",
    "in_shape = (128,128,3)\n",
    "in_image = Input(shape = in_shape)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(in_image)\n",
    "fe = LeakyReLU(alpha=0.2)(fe)\n",
    "fe = Conv2D(64, (4,4), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (4,4), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Flatten()(fe)\n",
    "fe = Dense(num_of_classes)(fe)\n",
    "c_out_layer = Activation('softmax')(fe)\n",
    "c_model = Model(in_image, c_out_layer)\n",
    "c_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "d_out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "d_model = Model(in_image,d_out_layer)\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5876 - accuracy: 0.0372 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 2/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5875 - accuracy: 0.0364 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 3/75\n",
      "39/39 [==============================] - 35s 888ms/step - loss: 10.5870 - accuracy: 0.0340 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 4/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5870 - accuracy: 0.0348 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 5/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5871 - accuracy: 0.0372 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 6/75\n",
      "39/39 [==============================] - 35s 888ms/step - loss: 10.5870 - accuracy: 0.0364 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 7/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5870 - accuracy: 0.0388 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 8/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5869 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 9/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.0307 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 10/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5868 - accuracy: 0.0331 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 11/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5870 - accuracy: 0.0331 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 12/75\n",
      "39/39 [==============================] - 35s 890ms/step - loss: 10.5868 - accuracy: 0.0307 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 13/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5868 - accuracy: 0.0323 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 14/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5868 - accuracy: 0.0299 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 15/75\n",
      "39/39 [==============================] - 34s 885ms/step - loss: 10.5870 - accuracy: 0.0323 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 16/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5868 - accuracy: 0.0331 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 17/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 18/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5868 - accuracy: 0.0396 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 19/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0380 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 20/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5868 - accuracy: 0.0663 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 21/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.2506 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 22/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.2061 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 23/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 24/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5867 - accuracy: 0.0445 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 25/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5868 - accuracy: 0.0639 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 26/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.0348 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 27/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0299 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 28/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.0525 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 29/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.0598 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 30/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 31/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5867 - accuracy: 0.1293 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 32/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.1205 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 33/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5867 - accuracy: 0.0396 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 34/75\n",
      "39/39 [==============================] - 34s 883ms/step - loss: 10.5869 - accuracy: 0.0493 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 35/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5868 - accuracy: 0.0679 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 36/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 37/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 38/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0307 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 39/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5867 - accuracy: 0.0671 - val_loss: 10.6038 - val_accuracy: 0.1032\n",
      "Epoch 40/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0833 - val_loss: 10.6038 - val_accuracy: 0.1032\n",
      "Epoch 41/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0711 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 42/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0364 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 43/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0631 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 44/75\n",
      "39/39 [==============================] - 34s 885ms/step - loss: 10.5867 - accuracy: 0.1261 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 45/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5867 - accuracy: 0.2458 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 46/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.3961 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 47/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0687 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 48/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5867 - accuracy: 0.0930 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 49/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0461 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 50/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0792 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 51/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.1811 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 52/75\n",
      "39/39 [==============================] - 34s 885ms/step - loss: 10.5867 - accuracy: 0.3444 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 53/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5867 - accuracy: 0.3961 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 54/75\n",
      "39/39 [==============================] - 34s 883ms/step - loss: 10.5867 - accuracy: 0.2078 - val_loss: 10.6038 - val_accuracy: 0.1032\n",
      "Epoch 55/75\n",
      "39/39 [==============================] - 34s 883ms/step - loss: 10.5867 - accuracy: 0.0744 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 56/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0800 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5867 - accuracy: 0.0493 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 58/75\n",
      "39/39 [==============================] - 34s 883ms/step - loss: 10.5867 - accuracy: 0.0744 - val_loss: 10.6038 - val_accuracy: 0.4452\n",
      "Epoch 59/75\n",
      "39/39 [==============================] - 34s 883ms/step - loss: 10.5867 - accuracy: 0.1415 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 60/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.1504 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 61/75\n",
      "39/39 [==============================] - 35s 891ms/step - loss: 10.5867 - accuracy: 0.1584 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 62/75\n",
      "39/39 [==============================] - 34s 885ms/step - loss: 10.5867 - accuracy: 0.0719 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 63/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0719 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 64/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0315 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 65/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0639 - val_loss: 10.6038 - val_accuracy: 0.0065\n",
      "Epoch 66/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5868 - accuracy: 0.0865 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 67/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.0857 - val_loss: 10.6038 - val_accuracy: 0.0065\n",
      "Epoch 68/75\n",
      "39/39 [==============================] - 34s 883ms/step - loss: 10.5867 - accuracy: 0.0081 - val_loss: 10.6038 - val_accuracy: 0.0065\n",
      "Epoch 69/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0517 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 70/75\n",
      "39/39 [==============================] - 35s 887ms/step - loss: 10.5868 - accuracy: 0.0388 - val_loss: 10.6038 - val_accuracy: 0.0387\n",
      "Epoch 71/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5867 - accuracy: 0.0558 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 72/75\n",
      "39/39 [==============================] - 34s 884ms/step - loss: 10.5867 - accuracy: 0.1908 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 73/75\n",
      "39/39 [==============================] - 35s 885ms/step - loss: 10.5870 - accuracy: 0.1617 - val_loss: 10.6038 - val_accuracy: 0.1355\n",
      "Epoch 74/75\n",
      "39/39 [==============================] - 35s 886ms/step - loss: 10.5870 - accuracy: 0.1011 - val_loss: 10.6038 - val_accuracy: 0.0452\n",
      "Epoch 75/75\n",
      "39/39 [==============================] - 34s 882ms/step - loss: 10.5868 - accuracy: 0.0396 - val_loss: 10.6038 - val_accuracy: 0.0452\n"
     ]
    }
   ],
   "source": [
    "batch_size  = int(32)\n",
    "X_val = np.array(X_val).astype('float32')\n",
    "X_train = np.array(X_train).astype('float32')\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "CNN.fit(X_train, y_train, batch_size=32,epochs=75,validation_data=(X_val, y_val))\n",
    "CNN.save('classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = c_model.predict(test_generator, 257/batch_size,workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65292775e-20, 1.80348865e-17, 7.03265154e-11, 1.07284805e-07,\n",
       "       1.20792421e-09, 4.48849738e-01, 5.50354600e-01, 7.95611937e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "# latent_dim = (128)\n",
    "# in_lat = Input(shape=(latent_dim,))\n",
    "# n_nodes = 128 * 8 * 8\n",
    "# gen = Dense(n_nodes)(in_lat)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# gen = keras.layers.Reshape((8, 8, 128))(gen)\n",
    "# # upsample to 16x16*3\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# # upsample to 32x32\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# #64x64\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# #128x128\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# out_layer = Conv2D(1, (8,8), activation='tanh', padding='same')(gen)\n",
    "# # define model\n",
    "# generator = keras.Model(in_lat, out_layer)\n",
    "\n",
    "generator = Sequential()\n",
    "latent_dim = 256\n",
    "# foundation for 4x4 image\n",
    "n_nodes = 256 * 4 * 4\n",
    "generator.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Reshape((4, 4, 256)))\n",
    "# upsample to 8x8\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 16x16\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 32x32\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 64x64\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 128x128\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# output layer\n",
    "generator.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "\n",
    "def define_gan(generator,discriminator ):\n",
    "    generative = keras.Sequential()\n",
    "    generative.add(generator)\n",
    "    generative.add(discriminator)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generative.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return generative\n",
    "                    \n",
    "            \n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    #generate points in the latent space\n",
    "    z_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = z_input.reshape(n_samples, latent_dim)\n",
    "    return z_input\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict(z_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return images, y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:14:47.459025 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 850ms/step - loss: 0.1370 - accuracy: 0.9750\n",
      "Epoch 2/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:14:57.141201 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 820ms/step - loss: 0.1150 - accuracy: 0.9781\n",
      "Epoch 3/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:11.419978 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 0.1784 - accuracy: 0.9625\n",
      "Epoch 4/35\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0723 - accuracy: 0.9896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:19.236618 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 641ms/step - loss: 0.0706 - accuracy: 0.9898\n",
      "Epoch 5/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:27.782449 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 678ms/step - loss: 0.1426 - accuracy: 0.9750\n",
      "Epoch 6/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:34.480936 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 587ms/step - loss: 0.1251 - accuracy: 0.9750\n",
      "Epoch 7/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:40.876661 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0886 - accuracy: 0.9844\n",
      "Epoch 8/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:46.526565 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 432ms/step - loss: 0.1547 - accuracy: 0.9656\n",
      "Epoch 9/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:54.071215 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 638ms/step - loss: 0.1175 - accuracy: 0.9781\n",
      "Epoch 10/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:59.077395 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 431ms/step - loss: 0.1792 - accuracy: 0.9797\n",
      "Epoch 11/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:04.079801 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 430ms/step - loss: 0.1348 - accuracy: 0.9719\n",
      "Epoch 12/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:10.092716 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 497ms/step - loss: 0.0434 - accuracy: 0.9937\n",
      "Epoch 13/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:15.455670 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 454ms/step - loss: 0.1321 - accuracy: 0.9750\n",
      "Epoch 14/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:19.862463 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 372ms/step - loss: 0.0865 - accuracy: 0.9844\n",
      "Epoch 15/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:25.335716 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 454ms/step - loss: 0.1325 - accuracy: 0.9719\n",
      "Epoch 16/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:32.121359 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 565ms/step - loss: 0.1381 - accuracy: 0.9729\n",
      "Epoch 17/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:36.383945 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 338ms/step - loss: 0.0693 - accuracy: 0.9875\n",
      "Epoch 18/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:40.280349 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 322ms/step - loss: 0.1454 - accuracy: 0.9688\n",
      "Epoch 19/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:44.370185 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 330ms/step - loss: 0.0482 - accuracy: 0.9898\n",
      "Epoch 20/35\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1349 - accuracy: 0.9722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:49.010016 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1323 - accuracy: 0.9729\n",
      "Epoch 21/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:53.489454 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 370ms/step - loss: 0.0903 - accuracy: 0.9812\n",
      "Epoch 22/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:58.897949 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 464ms/step - loss: 0.1417 - accuracy: 0.9719\n",
      "Epoch 23/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:03.889541 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 416ms/step - loss: 0.0824 - accuracy: 0.9844\n",
      "Epoch 24/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:08.131535 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1950 - accuracy: 0.9729\n",
      "Epoch 25/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:13.020853 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 418ms/step - loss: 0.1286 - accuracy: 0.9750\n",
      "Epoch 26/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:18.992322 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 532ms/step - loss: 0.1327 - accuracy: 0.9719\n",
      "Epoch 27/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:25.127360 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 556ms/step - loss: 0.1256 - accuracy: 0.9750\n",
      "Epoch 28/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:29.412031 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 346ms/step - loss: 0.0565 - accuracy: 0.9898\n",
      "Epoch 29/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:37.238067 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 705ms/step - loss: 0.0822 - accuracy: 0.9844\n",
      "Epoch 30/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:42.402155 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 448ms/step - loss: 0.0748 - accuracy: 0.9844\n",
      "Epoch 31/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:47.364375 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1429 - accuracy: 0.9656\n",
      "Epoch 32/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:51.727260 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1095 - accuracy: 0.9781\n",
      "Epoch 33/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:58.931210 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 656ms/step - loss: 0.1550 - accuracy: 0.9627\n",
      "Epoch 34/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:18:03.692818 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 413ms/step - loss: 0.1181 - accuracy: 0.9750\n",
      "Epoch 35/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:18:08.372949 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.1288 - accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"/home/josheen/projects/def-vinay/josheen/DL/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "my_callbacks = [tensorboard_callback,keras.callbacks.ModelCheckpoint(filepath = '/home/josheen/projects/def-vinay/josheen/DL/model.{epoch:02d}.h5'), keras.callbacks.EarlyStopping(patience = 2)]\n",
    "\n",
    "discriminator.fit(train_generator, epochs = 35, steps_per_epoch = 10, validation_data= val_generator, validation_steps = 200, callbacks = my_callbacks)\n",
    "discriminator.save_weights('discrim1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "def generate_unsupervised_samples(dataset, n_samples=8000):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    y = ones((n_samples, 1))\n",
    "    X = dataset[ix]\n",
    "    return X, y\n",
    "    \n",
    "def select_supervised_samples(dataset, labels, n_samples=104, n_classes=8):\n",
    "    n_per_class = int(n_samples / n_classes)\n",
    "    y = labels\n",
    "    X_list, y_list = list(), list()\n",
    "    for i in range(n_classes):\n",
    "        # get all images for this class\n",
    "        X_with_class = labels.index[labels['y'] == i].tolist()\n",
    "        # choose random instances\n",
    "        ix = randint(0, len(X_with_class), n_per_class)\n",
    "        # add to list\n",
    "        [X_list.append(dataset[j]) for j in ix]\n",
    "        [y_list.append(i) for j in ix]\n",
    "    return np.asarray(X_list), np.asarray(y_list)\n",
    " \n",
    "\n",
    "def summarize_performance(epoch, g_model, c_model, latent_dim, dataset,labels, n_samples=100):\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # evaluate the classifier model\n",
    "    X, y = dataset, labels\n",
    "    _, acc = c_model.evaluate(X, y, verbose=0)\n",
    "    print('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
    "\n",
    "def train(g_model, d_model,c_model, gan_model, dataset, labels,unlabeled, latent_dim, n_epochs=30, n_batch=10):\n",
    "    X_sup, y_sup = select_supervised_samples(dataset,labels)\n",
    "    print(X_sup.shape, y_sup.shape)\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    print('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], half_batch)\n",
    "        c_loss, c_acc = c_model.train_on_batch(Xsup_real, ysup_real)\n",
    "        # update unsupervised discriminator (d)\n",
    "        X_real, y_real = generate_unsupervised_samples(unlabeled, half_batch)\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        # summarize loss on this batch\n",
    "        # evaluate the model performance every so often\n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "            summarize_performance(i, g_model, c_model, latent_dim, dataset, labels)\n",
    "    c_model.save('classifier_model.h5')\n",
    "    g_model.save('GAN_model.h5')\n",
    "    d_model.save('discrim2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "left=115\n",
    "top=35\n",
    "right=243\n",
    "bottom=163\n",
    "\n",
    "train_files = []\n",
    "y_train = []\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "    y_train.append(row['Recovery']) \n",
    "    img = load_img(row['Address'])  # this is a PIL image\n",
    "    img1 = img.crop((left,top,right,bottom))\n",
    "    x = img_to_array(img1)\n",
    "    x = (x - 255.0) / 255.0\n",
    "    dataset.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 128, 128, 3) (104,)\n",
      "n_epochs=30, n_batch=10, 1/2=5, b/e=12, steps=360\n",
      "Classifier Accuracy: 17.244%\n",
      "Classifier Accuracy: 11.950%\n",
      "Classifier Accuracy: 25.886%\n",
      "Classifier Accuracy: 6.384%\n",
      "Classifier Accuracy: 9.576%\n",
      "Classifier Accuracy: 3.348%\n",
      "Classifier Accuracy: 20.670%\n",
      "Classifier Accuracy: 18.256%\n",
      "Classifier Accuracy: 8.252%\n",
      "Classifier Accuracy: 10.860%\n",
      "Classifier Accuracy: 9.420%\n",
      "Classifier Accuracy: 4.399%\n",
      "Classifier Accuracy: 10.549%\n",
      "Classifier Accuracy: 5.527%\n",
      "Classifier Accuracy: 7.162%\n",
      "Classifier Accuracy: 5.917%\n",
      "Classifier Accuracy: 7.007%\n",
      "Classifier Accuracy: 4.087%\n",
      "Classifier Accuracy: 25.730%\n",
      "Classifier Accuracy: 5.566%\n",
      "Classifier Accuracy: 4.632%\n",
      "Classifier Accuracy: 4.282%\n",
      "Classifier Accuracy: 21.643%\n",
      "Classifier Accuracy: 26.508%\n",
      "Classifier Accuracy: 4.243%\n",
      "Classifier Accuracy: 5.060%\n",
      "Classifier Accuracy: 24.445%\n",
      "Classifier Accuracy: 19.112%\n",
      "Classifier Accuracy: 27.715%\n",
      "Classifier Accuracy: 26.547%\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "unsupervised_data = np.array(unsupervised_data)\n",
    "labels = pd.DataFrame(y_train,columns = ['y'])\n",
    "generator.load_weights('GAN_Model.h5')\n",
    "d_model.load_weights('discrim2.h5')\n",
    "c_model.load_weights('classifier_model.h5')\n",
    "generative = define_gan(generator,d_model)\n",
    "train(generator,d_model, c_model, generative, dataset,labels, unsupervised_data, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/josheen/projects/def-vinay/josheen/DL/generated_images'\n",
    "img_loc = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "\n",
    "generate_data = ImageDataGenerator(\n",
    "    rescale = 1./255, rotation_range = 5, width_shift_range = 0.2, height_shift_range = 0.2, shear_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip = True, fill_mode='nearest')\n",
    "\n",
    "for index, row in img_loc.iterrows():\n",
    "    image = load_img(row['Address'])\n",
    "    image = np.expand_dims(img_to_array(image),0)\n",
    "    generate_data.fit(image)\n",
    "    for x, val in zip(generate_data.flow(image,save_to_dir=save_dir,save_prefix='aug',save_format='png'),range(5)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "left=115\n",
    "top=35\n",
    "right=243\n",
    "bottom=163\n",
    "unsupervised_data = []\n",
    "for file in os.listdir('/home/josheen/projects/def-vinay/josheen/DL/generated_images'):\n",
    "    img1 = img.crop((left,top,right,bottom))\n",
    "    x = img_to_array(img1)\n",
    "    x = (x - 255.0) / 255.0\n",
    "    unsupervised_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "categorical_train = []\n",
    "for val in y_train:\n",
    "    if val <= 5:\n",
    "        categorical_train.append(0)\n",
    "    elif val > 5 and val <= 10:\n",
    "        categorical_train.append(1)\n",
    "    elif val > 10 and val<= 15:\n",
    "        categorical_train.append(2)\n",
    "    elif val > 15 and val<= 20:\n",
    "        categorical_train.append(3)\n",
    "    elif val > 20 and val<= 25:\n",
    "        categorical_train.append(4)\n",
    "    elif val > 25 and val <= 30:\n",
    "        categorical_train.append(5)\n",
    "    elif val > 30 and val <= 35:\n",
    "        categorical_train.append(6)\n",
    "    elif val >35:\n",
    "        categorical_train.append(7)\n",
    "y_train = categorical_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682\n"
     ]
    }
   ],
   "source": [
    "print(len(unsupervised_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
