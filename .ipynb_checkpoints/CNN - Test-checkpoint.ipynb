{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import pandas as pd\n",
    "import matplotlib as mplt\n",
    "import re\n",
    "from keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'/home/josheen/projects/def-vinay/josheen/DL/Figure13model/runs_excel_files'\n",
    "dfs = []\n",
    "for runs in os.listdir(directory):\n",
    "    R = pd.read_excel(os.path.join(directory,runs))\n",
    "    rnum = os.path.splitext(runs)[0]\n",
    "    R.head()\n",
    "    R['Run'] = int(rnum[1])\n",
    "    R.head()\n",
    "    dfs.append(R)\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = \"/home/josheen/projects/def-vinay/josheen/DL/Figure13model/mapped_data/AllRunsmapped.csv\"\n",
    "directory = \"/home/josheen/projects/def-vinay/josheen/DL/\"\n",
    "df = pd.read_csv(FileName)\n",
    "for index, row in df.iterrows():\n",
    "    address = row['Address']\n",
    "    new = address.replace(\"\\\\\", \"/\")\n",
    "    add_index = address.find('Figure13model')\n",
    "    new_filename = os.path.join(directory, new[add_index:])\n",
    "    df.at[index, 'Address'] = new_filename\n",
    "    \n",
    "df.to_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-be56f17be050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Recovery'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is a PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    299\u001b[0m   \"\"\"\n\u001b[1;32m    300\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 301\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "left=115\n",
    "top=35\n",
    "right=243\n",
    "bottom=163\n",
    "\n",
    "train_files = []\n",
    "y_train = []\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "    y_train.append(row['Recovery']) \n",
    "    img = load_img(row['Address'])  # this is a PIL image\n",
    "    \n",
    "    img1 = img.crop((left,top,right,bottom))\n",
    "    \n",
    "    #img2 =img1.thumbnail((128, 128))\n",
    "    x = img_to_array(img1)\n",
    "    #x = x.reshape((3, 128, 128))\n",
    "    #x = (x - 128.0) / 128.0\n",
    "    x = (x - 255.0) / 255.0\n",
    "    dataset.append(x)\n",
    "    \n",
    "y_train1 = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "dataset = test\n",
    "y_train1 = test['Recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2569, 257]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7b7e2dad3893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mval_to_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_to_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_to_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2125\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m    292\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 257\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2569, 257]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "num_classes = 8\n",
    "for val in y_train1:\n",
    "    categorical_train = []\n",
    "    for index, row in gen.iterrows():\n",
    "        val = row['Recovery']\n",
    "        if val <= 5:\n",
    "            categorical_train.append(0)\n",
    "        elif val > 5 and val <= 10:\n",
    "            categorical_train.append(1)\n",
    "        elif val > 10 and val<= 15:\n",
    "            categorical_train.append(2)\n",
    "        elif val > 15 and val<= 20:\n",
    "            categorical_train.append(3)\n",
    "        elif val > 20 and val<= 25:\n",
    "            categorical_train.append(4)\n",
    "        elif val > 25 and val <= 30:\n",
    "            categorical_train.append(5)\n",
    "        elif val > 30 and val <= 35:\n",
    "            categorical_train.append(6)\n",
    "        elif val >35:\n",
    "            categorical_train.append(7)\n",
    "        y_train = categorical_train\n",
    "\n",
    "test_to_train=0.2\n",
    "val_to_test=0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=test_to_train, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=val_to_test, random_state=33)\n",
    "\n",
    "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained CNN - VGG16 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes: we should look into making generators, accuracy does not seem to go higher than MAE = 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 16,820,584\n",
      "Trainable params: 2,105,896\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top=False, input_shape=(128,128,3))\n",
    "conv_base.trainable = False \n",
    "CNN = models.Sequential()\n",
    "CNN.add(conv_base)\n",
    "CNN.add(layers.Flatten())\n",
    "CNN.add(layers.Dense(256, activation='relu'))\n",
    "CNN.add(layers.Dropout(0.2))\n",
    "CNN.add(layers.Dense(32, activation='relu'))\n",
    "CNN.add(layers.Dropout(0.3))\n",
    "CNN.add(layers.Dense(8, activation = 'softmax'))\n",
    "CNN.summary()\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "CNN.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "20/20 [==============================] - 32s 2s/step - loss: 27.9036 - mae: 4.1165 - val_loss: 4.7617 - val_mae: 1.6448\n",
      "Epoch 2/75\n",
      "20/20 [==============================] - 32s 2s/step - loss: 12.5647 - mae: 2.8332 - val_loss: 2.8762 - val_mae: 1.2607\n",
      "Epoch 3/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 11.3813 - mae: 2.6085 - val_loss: 3.0765 - val_mae: 1.2197\n",
      "Epoch 4/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 9.7415 - mae: 2.4728 - val_loss: 11.8371 - val_mae: 3.1843\n",
      "Epoch 5/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 11.1783 - mae: 2.6532 - val_loss: 2.5852 - val_mae: 1.2561\n",
      "Epoch 6/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 9.2012 - mae: 2.4312 - val_loss: 4.7706 - val_mae: 1.8183\n",
      "Epoch 7/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 8.0253 - mae: 2.2152 - val_loss: 1.8967 - val_mae: 1.0165\n",
      "Epoch 8/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 9.8062 - mae: 2.4783 - val_loss: 4.0685 - val_mae: 1.6450\n",
      "Epoch 9/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.9766 - mae: 2.2200 - val_loss: 11.5158 - val_mae: 3.0984\n",
      "Epoch 10/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.5457 - mae: 2.1447 - val_loss: 1.9368 - val_mae: 1.0285\n",
      "Epoch 11/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 8.1747 - mae: 2.2957 - val_loss: 1.8695 - val_mae: 1.0188\n",
      "Epoch 12/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 8.7803 - mae: 2.3064 - val_loss: 2.1542 - val_mae: 1.0980\n",
      "Epoch 13/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.4703 - mae: 2.1586 - val_loss: 3.9279 - val_mae: 1.7048\n",
      "Epoch 14/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.6418 - mae: 2.0252 - val_loss: 4.6842 - val_mae: 1.8370\n",
      "Epoch 15/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 8.0640 - mae: 2.1806 - val_loss: 2.2507 - val_mae: 1.1525\n",
      "Epoch 16/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.4354 - mae: 2.1682 - val_loss: 2.1861 - val_mae: 1.0993\n",
      "Epoch 17/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 7.0114 - mae: 2.0843 - val_loss: 2.8603 - val_mae: 1.4371\n",
      "Epoch 18/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 7.0630 - mae: 2.0992 - val_loss: 3.8276 - val_mae: 1.6200\n",
      "Epoch 19/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.3303 - mae: 2.1385 - val_loss: 4.9983 - val_mae: 1.9289\n",
      "Epoch 20/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.8408 - mae: 2.1956 - val_loss: 1.9205 - val_mae: 1.0271\n",
      "Epoch 21/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.4084 - mae: 1.8305 - val_loss: 3.4342 - val_mae: 1.4933\n",
      "Epoch 22/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.1376 - mae: 2.0798 - val_loss: 1.6990 - val_mae: 0.9472\n",
      "Epoch 23/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.9890 - mae: 1.9433 - val_loss: 6.6769 - val_mae: 2.3398\n",
      "Epoch 24/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 7.0412 - mae: 2.0781 - val_loss: 18.3573 - val_mae: 4.0064\n",
      "Epoch 25/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 7.3701 - mae: 2.1297 - val_loss: 4.0288 - val_mae: 1.6340\n",
      "Epoch 26/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 6.5437 - mae: 2.0098 - val_loss: 1.6543 - val_mae: 0.9876\n",
      "Epoch 27/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.2886 - mae: 1.9787 - val_loss: 4.4649 - val_mae: 1.8700\n",
      "Epoch 28/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.4140 - mae: 2.0008 - val_loss: 2.8290 - val_mae: 1.3299\n",
      "Epoch 29/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 6.0351 - mae: 1.9277 - val_loss: 3.3817 - val_mae: 1.5370\n",
      "Epoch 30/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 5.8907 - mae: 1.8801 - val_loss: 2.6096 - val_mae: 1.2646\n",
      "Epoch 31/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.2522 - mae: 1.9405 - val_loss: 1.5521 - val_mae: 0.9363\n",
      "Epoch 32/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 6.1488 - mae: 1.9217 - val_loss: 1.8314 - val_mae: 0.9896\n",
      "Epoch 33/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.9540 - mae: 1.9467 - val_loss: 1.9939 - val_mae: 1.0705\n",
      "Epoch 34/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 5.5838 - mae: 1.8675 - val_loss: 1.6281 - val_mae: 0.9531\n",
      "Epoch 35/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.5732 - mae: 2.0044 - val_loss: 6.5993 - val_mae: 2.3342\n",
      "Epoch 36/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.3483 - mae: 1.9989 - val_loss: 10.6976 - val_mae: 3.0231\n",
      "Epoch 37/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.2839 - mae: 1.9738 - val_loss: 1.5905 - val_mae: 0.9294\n",
      "Epoch 38/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.5944 - mae: 2.0130 - val_loss: 1.5894 - val_mae: 0.9611\n",
      "Epoch 39/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.8622 - mae: 1.9050 - val_loss: 7.5454 - val_mae: 2.4857\n",
      "Epoch 40/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 5.5022 - mae: 1.8469 - val_loss: 1.5604 - val_mae: 0.9105\n",
      "Epoch 41/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.1438 - mae: 1.9442 - val_loss: 2.8405 - val_mae: 1.4554\n",
      "Epoch 42/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 5.6133 - mae: 1.8663 - val_loss: 5.3124 - val_mae: 1.9567\n",
      "Epoch 43/75\n",
      "20/20 [==============================] - 34s 2s/step - loss: 6.6710 - mae: 2.0189 - val_loss: 15.2876 - val_mae: 3.6465\n",
      "Epoch 44/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 4.9444 - mae: 1.7586 - val_loss: 9.0067 - val_mae: 2.6981\n",
      "Epoch 45/75\n",
      "20/20 [==============================] - 32s 2s/step - loss: 6.1444 - mae: 1.9650 - val_loss: 1.5631 - val_mae: 0.9284\n",
      "Epoch 46/75\n",
      "20/20 [==============================] - 32s 2s/step - loss: 6.6115 - mae: 2.0261 - val_loss: 1.7950 - val_mae: 1.0402\n",
      "Epoch 47/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.3289 - mae: 1.9470 - val_loss: 7.0120 - val_mae: 2.3725\n",
      "Epoch 48/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.9182 - mae: 1.8968 - val_loss: 2.7820 - val_mae: 1.3777\n",
      "Epoch 49/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.3843 - mae: 1.9261 - val_loss: 6.5669 - val_mae: 2.2685\n",
      "Epoch 50/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.1810 - mae: 1.9231 - val_loss: 2.7974 - val_mae: 1.4117\n",
      "Epoch 51/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.7014 - mae: 1.8619 - val_loss: 3.8074 - val_mae: 1.7039\n",
      "Epoch 52/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.0759 - mae: 1.9310 - val_loss: 1.6212 - val_mae: 0.9480\n",
      "Epoch 53/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.3302 - mae: 1.9915 - val_loss: 8.6829 - val_mae: 2.6513\n",
      "Epoch 54/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.7660 - mae: 1.8510 - val_loss: 8.0122 - val_mae: 2.5945\n",
      "Epoch 55/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.8789 - mae: 1.8725 - val_loss: 1.9031 - val_mae: 1.0929\n",
      "Epoch 56/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.9847 - mae: 1.9320 - val_loss: 2.0135 - val_mae: 1.0725\n",
      "Epoch 57/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.1972 - mae: 1.7960 - val_loss: 3.1812 - val_mae: 1.5539\n",
      "Epoch 58/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.2157 - mae: 1.8920 - val_loss: 4.3623 - val_mae: 1.8242\n",
      "Epoch 59/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.4792 - mae: 1.8015 - val_loss: 2.4583 - val_mae: 1.2669\n",
      "Epoch 60/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.0160 - mae: 1.7372 - val_loss: 4.5736 - val_mae: 1.8309\n",
      "Epoch 61/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.4917 - mae: 1.8406 - val_loss: 5.3874 - val_mae: 2.0293\n",
      "Epoch 62/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.8962 - mae: 1.9039 - val_loss: 3.6960 - val_mae: 1.6038\n",
      "Epoch 63/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.8556 - mae: 1.8850 - val_loss: 1.7383 - val_mae: 1.0297\n",
      "Epoch 64/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.8460 - mae: 1.8843 - val_loss: 13.2692 - val_mae: 3.4011\n",
      "Epoch 65/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.5630 - mae: 1.8415 - val_loss: 1.4806 - val_mae: 0.8982\n",
      "Epoch 66/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 4.9753 - mae: 1.7450 - val_loss: 2.6966 - val_mae: 1.3840\n",
      "Epoch 67/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.2401 - mae: 1.9446 - val_loss: 2.6433 - val_mae: 1.3930\n",
      "Epoch 68/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.0330 - mae: 1.9275 - val_loss: 1.4348 - val_mae: 0.8844\n",
      "Epoch 69/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.5594 - mae: 1.7904 - val_loss: 3.3589 - val_mae: 1.5821\n",
      "Epoch 70/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.0343 - mae: 1.9301 - val_loss: 2.6397 - val_mae: 1.3882\n",
      "Epoch 71/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.3555 - mae: 1.9771 - val_loss: 5.7962 - val_mae: 2.1292\n",
      "Epoch 72/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.1561 - mae: 1.9405 - val_loss: 4.2297 - val_mae: 1.7657\n",
      "Epoch 73/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.5592 - mae: 1.8472 - val_loss: 2.1954 - val_mae: 1.1834\n",
      "Epoch 74/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 6.2775 - mae: 1.9168 - val_loss: 6.6647 - val_mae: 2.3214\n",
      "Epoch 75/75\n",
      "20/20 [==============================] - 33s 2s/step - loss: 5.4807 - mae: 1.8316 - val_loss: 8.1674 - val_mae: 2.5980\n"
     ]
    }
   ],
   "source": [
    "CNN.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "my_callbacks = EarlyStopping(monitor=\"mean_absolute_error\", patience=6, mode=\"auto\")\n",
    "X_val = np.array(X_val)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "CNN.fit(X_train, y_train, batch_size=32,epochs=75,validation_data=(X_val, y_val))\n",
    "model = CNN.save('/home/josheen/projects/def-vinay/josheen/DL/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_train=0.2\n",
    "val_to_test=0.5\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['Address'], y_train1, test_size=test_to_train, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=val_to_test, random_state=33)\n",
    "\n",
    "train_gen = pd.DataFrame(X_train, columns=['Address'])\n",
    "train_gen['Recovery'] = y_train\n",
    "\n",
    "test_gen = pd.DataFrame(X_test, columns=['Address'])\n",
    "test_gen['Recovery'] = y_test\n",
    "\n",
    "val_gen = pd.DataFrame(X_val, columns=['Address'])\n",
    "val_gen['Recovery'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider splitting from 0-3 3-6 6-9 9-12 12-15 15-18 18-21 7 classes\n",
    "num_classes = 8\n",
    "for gen in [train_gen, test_gen, val_gen]:\n",
    "    categorical_train = []\n",
    "    for index, row in gen.iterrows():\n",
    "        val = row['Recovery']\n",
    "        if val <= 5:\n",
    "            categorical_train.append(0)\n",
    "        elif val > 5 and val <= 10:\n",
    "            categorical_train.append(1)\n",
    "        elif val > 10 and val<= 15:\n",
    "            categorical_train.append(2)\n",
    "        elif val > 15 and val<= 20:\n",
    "            categorical_train.append(3)\n",
    "        elif val > 20 and val<= 25:\n",
    "            categorical_train.append(4)\n",
    "        elif val > 25 and val <= 30:\n",
    "            categorical_train.append(5)\n",
    "        elif val > 30 and val <= 35:\n",
    "            categorical_train.append(6)\n",
    "        elif val >35:\n",
    "            categorical_train.append(7)\n",
    "    gen['Recovery'] = categorical_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_gen['Recovery'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2055 validated image filenames.\n",
      "Found 257 validated image filenames.\n",
      "Found 257 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255, rotation_range = 5, width_shift_range = 0.05, height_shift_range = 0.05, shear_range=0.05,\n",
    "    zoom_range=0.08, horizontal_flip = True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_gen, directory = None, x_col = 'Address', y_col = 'Recovery', target_size = (128,128),class_mode = 'raw')\n",
    "test_generator = test_datagen.flow_from_dataframe(test_gen, directory = None, x_col = 'Address', y_col = 'Recovery', target_size = (128,128), class_mode = 'raw')\n",
    "val_generator = val_datagen.flow_from_dataframe(val_gen, directory = None, x_col = 'Address', y_col = 'Recovery', target_size = (128,128), class_mode = 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras import Model \n",
    "\n",
    "initialWeights = keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=None)\n",
    "num_of_classes = 8\n",
    "in_shape = (128,128,3)\n",
    "in_image = Input(shape = in_shape)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(in_image)\n",
    "fe = LeakyReLU(alpha=0.2)(fe)\n",
    "fe = Conv2D(64, (4,4), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (4,4), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Conv2D(64, (3,3), strides=(2, 2), padding='same', kernel_initializer=initialWeights)(fe)\n",
    "fe = BatchNormalization()(fe)\n",
    "fe = Flatten()(fe)\n",
    "fe = Dense(num_of_classes)(fe)\n",
    "c_out_layer = Activation('softmax')(fe)\n",
    "c_model = Model(in_image, c_out_layer)\n",
    "c_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "d_out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "d_model = Model(in_image,d_out_layer)\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "X_val = X_val.to_numpy()\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "CNN.fit(X_train,y_train,\n",
    "        steps_per_epoch=2055//batch_size,\n",
    "        epochs=30,\n",
    "        validation_data=(X_val, y_val),\n",
    "        validation_batch_size = 8)\n",
    "\n",
    "CNN.save('classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = c_model.predict(test_generator, 257/batch_size,workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65292775e-20, 1.80348865e-17, 7.03265154e-11, 1.07284805e-07,\n",
       "       1.20792421e-09, 4.48849738e-01, 5.50354600e-01, 7.95611937e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "# latent_dim = (128)\n",
    "# in_lat = Input(shape=(latent_dim,))\n",
    "# n_nodes = 128 * 8 * 8\n",
    "# gen = Dense(n_nodes)(in_lat)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# gen = keras.layers.Reshape((8, 8, 128))(gen)\n",
    "# # upsample to 16x16*3\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# # upsample to 32x32\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# #64x64\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# #128x128\n",
    "# gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "# gen = LeakyReLU(alpha=0.2)(gen)\n",
    "# out_layer = Conv2D(1, (8,8), activation='tanh', padding='same')(gen)\n",
    "# # define model\n",
    "# generator = keras.Model(in_lat, out_layer)\n",
    "\n",
    "generator = Sequential()\n",
    "latent_dim = 256\n",
    "# foundation for 4x4 image\n",
    "n_nodes = 256 * 4 * 4\n",
    "generator.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Reshape((4, 4, 256)))\n",
    "# upsample to 8x8\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 16x16\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 32x32\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 64x64\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 128x128\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation='relu', kernel_initializer=initialWeights))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# output layer\n",
    "generator.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "\n",
    "def define_gan(generator,discriminator ):\n",
    "    generative = keras.Sequential()\n",
    "    generative.add(generator)\n",
    "    generative.add(discriminator)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generative.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return generative\n",
    "                    \n",
    "            \n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    #generate points in the latent space\n",
    "    z_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = z_input.reshape(n_samples, latent_dim)\n",
    "    return z_input\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict(z_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return images, y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:14:47.459025 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 850ms/step - loss: 0.1370 - accuracy: 0.9750\n",
      "Epoch 2/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:14:57.141201 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 820ms/step - loss: 0.1150 - accuracy: 0.9781\n",
      "Epoch 3/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:11.419978 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 0.1784 - accuracy: 0.9625\n",
      "Epoch 4/35\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0723 - accuracy: 0.9896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:19.236618 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 641ms/step - loss: 0.0706 - accuracy: 0.9898\n",
      "Epoch 5/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:27.782449 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 678ms/step - loss: 0.1426 - accuracy: 0.9750\n",
      "Epoch 6/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:34.480936 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 587ms/step - loss: 0.1251 - accuracy: 0.9750\n",
      "Epoch 7/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:40.876661 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0886 - accuracy: 0.9844\n",
      "Epoch 8/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:46.526565 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 432ms/step - loss: 0.1547 - accuracy: 0.9656\n",
      "Epoch 9/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:54.071215 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 638ms/step - loss: 0.1175 - accuracy: 0.9781\n",
      "Epoch 10/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:15:59.077395 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 431ms/step - loss: 0.1792 - accuracy: 0.9797\n",
      "Epoch 11/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:04.079801 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 430ms/step - loss: 0.1348 - accuracy: 0.9719\n",
      "Epoch 12/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:10.092716 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 497ms/step - loss: 0.0434 - accuracy: 0.9937\n",
      "Epoch 13/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:15.455670 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 454ms/step - loss: 0.1321 - accuracy: 0.9750\n",
      "Epoch 14/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:19.862463 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 372ms/step - loss: 0.0865 - accuracy: 0.9844\n",
      "Epoch 15/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:25.335716 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 454ms/step - loss: 0.1325 - accuracy: 0.9719\n",
      "Epoch 16/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:32.121359 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 565ms/step - loss: 0.1381 - accuracy: 0.9729\n",
      "Epoch 17/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:36.383945 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 338ms/step - loss: 0.0693 - accuracy: 0.9875\n",
      "Epoch 18/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:40.280349 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 322ms/step - loss: 0.1454 - accuracy: 0.9688\n",
      "Epoch 19/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:44.370185 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 330ms/step - loss: 0.0482 - accuracy: 0.9898\n",
      "Epoch 20/35\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1349 - accuracy: 0.9722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:49.010016 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1323 - accuracy: 0.9729\n",
      "Epoch 21/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:53.489454 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 370ms/step - loss: 0.0903 - accuracy: 0.9812\n",
      "Epoch 22/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:16:58.897949 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 464ms/step - loss: 0.1417 - accuracy: 0.9719\n",
      "Epoch 23/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:03.889541 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 416ms/step - loss: 0.0824 - accuracy: 0.9844\n",
      "Epoch 24/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:08.131535 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1950 - accuracy: 0.9729\n",
      "Epoch 25/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:13.020853 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 418ms/step - loss: 0.1286 - accuracy: 0.9750\n",
      "Epoch 26/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:18.992322 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 532ms/step - loss: 0.1327 - accuracy: 0.9719\n",
      "Epoch 27/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:25.127360 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 556ms/step - loss: 0.1256 - accuracy: 0.9750\n",
      "Epoch 28/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:29.412031 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 346ms/step - loss: 0.0565 - accuracy: 0.9898\n",
      "Epoch 29/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:37.238067 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 705ms/step - loss: 0.0822 - accuracy: 0.9844\n",
      "Epoch 30/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:42.402155 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 448ms/step - loss: 0.0748 - accuracy: 0.9844\n",
      "Epoch 31/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:47.364375 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1429 - accuracy: 0.9656\n",
      "Epoch 32/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:51.727260 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1095 - accuracy: 0.9781\n",
      "Epoch 33/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:17:58.931210 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 656ms/step - loss: 0.1550 - accuracy: 0.9627\n",
      "Epoch 34/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:18:03.692818 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 413ms/step - loss: 0.1181 - accuracy: 0.9750\n",
      "Epoch 35/35\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 20:18:08.372949 47953444966080 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.1288 - accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"/home/josheen/projects/def-vinay/josheen/DL/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "my_callbacks = [tensorboard_callback,keras.callbacks.ModelCheckpoint(filepath = '/home/josheen/projects/def-vinay/josheen/DL/model.{epoch:02d}.h5'), keras.callbacks.EarlyStopping(patience = 2)]\n",
    "\n",
    "discriminator.fit(train_generator, epochs = 35, steps_per_epoch = 10, validation_data= val_generator, validation_steps = 200, callbacks = my_callbacks)\n",
    "discriminator.save_weights('discrim1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "def generate_unsupervised_samples(dataset, n_samples=8000):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    y = ones((n_samples, 1))\n",
    "    X = dataset[ix]\n",
    "    return X, y\n",
    "    \n",
    "def select_supervised_samples(dataset, labels, n_samples=104, n_classes=8):\n",
    "    n_per_class = int(n_samples / n_classes)\n",
    "    y = labels\n",
    "    X_list, y_list = list(), list()\n",
    "    for i in range(n_classes):\n",
    "        # get all images for this class\n",
    "        X_with_class = labels.index[labels['y'] == i].tolist()\n",
    "        # choose random instances\n",
    "        ix = randint(0, len(X_with_class), n_per_class)\n",
    "        # add to list\n",
    "        [X_list.append(dataset[j]) for j in ix]\n",
    "        [y_list.append(i) for j in ix]\n",
    "    return np.asarray(X_list), np.asarray(y_list)\n",
    " \n",
    "\n",
    "def summarize_performance(epoch, g_model, c_model, latent_dim, dataset,labels, n_samples=100):\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # evaluate the classifier model\n",
    "    X, y = dataset, labels\n",
    "    _, acc = c_model.evaluate(X, y, verbose=0)\n",
    "    print('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
    "\n",
    "def train(g_model, d_model,c_model, gan_model, dataset, labels,unlabeled, latent_dim, n_epochs=30, n_batch=10):\n",
    "    X_sup, y_sup = select_supervised_samples(dataset,labels)\n",
    "    print(X_sup.shape, y_sup.shape)\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    print('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # update supervised discriminator (c)\n",
    "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], half_batch)\n",
    "        c_loss, c_acc = c_model.train_on_batch(Xsup_real, ysup_real)\n",
    "        # update unsupervised discriminator (d)\n",
    "        X_real, y_real = generate_unsupervised_samples(unlabeled, half_batch)\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        # update generator (g)\n",
    "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        # summarize loss on this batch\n",
    "        # evaluate the model performance every so often\n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "            summarize_performance(i, g_model, c_model, latent_dim, dataset, labels)\n",
    "    c_model.save('classifier_model.h5')\n",
    "    g_model.save('GAN_model.h5')\n",
    "    d_model.save('discrim2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "left=115\n",
    "top=35\n",
    "right=243\n",
    "bottom=163\n",
    "\n",
    "train_files = []\n",
    "y_train = []\n",
    "dataset = []\n",
    "for index, row in df.iterrows():\n",
    "    y_train.append(row['Recovery']) \n",
    "    img = load_img(row['Address'])  # this is a PIL image\n",
    "    img1 = img.crop((left,top,right,bottom))\n",
    "    x = img_to_array(img1)\n",
    "    x = (x - 255.0) / 255.0\n",
    "    dataset.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 128, 128, 3) (104,)\n",
      "n_epochs=30, n_batch=10, 1/2=5, b/e=12, steps=360\n",
      "Classifier Accuracy: 17.244%\n",
      "Classifier Accuracy: 11.950%\n",
      "Classifier Accuracy: 25.886%\n",
      "Classifier Accuracy: 6.384%\n",
      "Classifier Accuracy: 9.576%\n",
      "Classifier Accuracy: 3.348%\n",
      "Classifier Accuracy: 20.670%\n",
      "Classifier Accuracy: 18.256%\n",
      "Classifier Accuracy: 8.252%\n",
      "Classifier Accuracy: 10.860%\n",
      "Classifier Accuracy: 9.420%\n",
      "Classifier Accuracy: 4.399%\n",
      "Classifier Accuracy: 10.549%\n",
      "Classifier Accuracy: 5.527%\n",
      "Classifier Accuracy: 7.162%\n",
      "Classifier Accuracy: 5.917%\n",
      "Classifier Accuracy: 7.007%\n",
      "Classifier Accuracy: 4.087%\n",
      "Classifier Accuracy: 25.730%\n",
      "Classifier Accuracy: 5.566%\n",
      "Classifier Accuracy: 4.632%\n",
      "Classifier Accuracy: 4.282%\n",
      "Classifier Accuracy: 21.643%\n",
      "Classifier Accuracy: 26.508%\n",
      "Classifier Accuracy: 4.243%\n",
      "Classifier Accuracy: 5.060%\n",
      "Classifier Accuracy: 24.445%\n",
      "Classifier Accuracy: 19.112%\n",
      "Classifier Accuracy: 27.715%\n",
      "Classifier Accuracy: 26.547%\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "unsupervised_data = np.array(unsupervised_data)\n",
    "labels = pd.DataFrame(y_train,columns = ['y'])\n",
    "generator.load_weights('GAN_Model.h5')\n",
    "d_model.load_weights('discrim2.h5')\n",
    "c_model.load_weights('classifier_model.h5')\n",
    "generative = define_gan(generator,d_model)\n",
    "train(generator,d_model, c_model, generative, dataset,labels, unsupervised_data, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/josheen/projects/def-vinay/josheen/DL/generated_images'\n",
    "img_loc = pd.read_csv('/home/josheen/projects/def-vinay/josheen/DL/saved_df.csv')\n",
    "\n",
    "generate_data = ImageDataGenerator(\n",
    "    rescale = 1./255, rotation_range = 5, width_shift_range = 0.2, height_shift_range = 0.2, shear_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip = True, fill_mode='nearest')\n",
    "\n",
    "for index, row in img_loc.iterrows():\n",
    "    image = load_img(row['Address'])\n",
    "    image = np.expand_dims(img_to_array(image),0)\n",
    "    generate_data.fit(image)\n",
    "    for x, val in zip(generate_data.flow(image,save_to_dir=save_dir,save_prefix='aug',save_format='png'),range(5)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "left=115\n",
    "top=35\n",
    "right=243\n",
    "bottom=163\n",
    "unsupervised_data = []\n",
    "for file in os.listdir('/home/josheen/projects/def-vinay/josheen/DL/generated_images'):\n",
    "    img1 = img.crop((left,top,right,bottom))\n",
    "    x = img_to_array(img1)\n",
    "    x = (x - 255.0) / 255.0\n",
    "    unsupervised_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "categorical_train = []\n",
    "for val in y_train:\n",
    "    if val <= 5:\n",
    "        categorical_train.append(0)\n",
    "    elif val > 5 and val <= 10:\n",
    "        categorical_train.append(1)\n",
    "    elif val > 10 and val<= 15:\n",
    "        categorical_train.append(2)\n",
    "    elif val > 15 and val<= 20:\n",
    "        categorical_train.append(3)\n",
    "    elif val > 20 and val<= 25:\n",
    "        categorical_train.append(4)\n",
    "    elif val > 25 and val <= 30:\n",
    "        categorical_train.append(5)\n",
    "    elif val > 30 and val <= 35:\n",
    "        categorical_train.append(6)\n",
    "    elif val >35:\n",
    "        categorical_train.append(7)\n",
    "y_train = categorical_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682\n"
     ]
    }
   ],
   "source": [
    "print(len(unsupervised_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
